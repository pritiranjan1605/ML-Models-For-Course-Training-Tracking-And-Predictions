{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a15c802",
   "metadata": {},
   "source": [
    "# NLP-Based Sentiment Classification using Advanced Techniques\n",
    "## Transformer Models, Embeddings, and Deep Learning for Employee Feedback Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fce2c6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NLTK data...\n",
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"Downloading NLTK data...\")\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f1a428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split (80-20):\n",
      "  Total records: 500\n",
      "  Training set: 400 (80.0%)\n",
      "  Test set: 100 (20.0%)\n",
      "\n",
      "Columns: ['Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result', 'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback', 'Sentiment']\n",
      "\n",
      "Sentiment Distribution:\n",
      "Training set:\n",
      "  negative: 85 (21.2%)\n",
      "  neutral: 137 (34.2%)\n",
      "  positive: 178 (44.5%)\n",
      "Test set:\n",
      "  negative: 21 (21.0%)\n",
      "  neutral: 34 (34.0%)\n",
      "  positive: 45 (45.0%)\n"
     ]
    }
   ],
   "source": [
    "full_df = pd.read_csv('../NLP_Remark_Analysis/training_data_complete.csv')\n",
    "train_df, test_df = train_test_split(full_df, test_size=0.2, random_state=42, stratify=full_df['Sentiment'])\n",
    "\n",
    "print(\"Train-Test Split (80-20):\")\n",
    "print(f\"  Total records: {len(full_df)}\")\n",
    "print(f\"  Training set: {len(train_df)} ({len(train_df)/len(full_df):.1%})\")\n",
    "print(f\"  Test set: {len(test_df)} ({len(test_df)/len(full_df):.1%})\")\n",
    "print(f\"\\nColumns: {list(train_df.columns)}\")\n",
    "\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(\"Training set:\")\n",
    "for sentiment in sorted(train_df['Sentiment'].unique()):\n",
    "    count = (train_df['Sentiment'] == sentiment).sum()\n",
    "    pct = round(count / len(train_df) * 100, 1)\n",
    "    print(f\"  {sentiment}: {count} ({pct}%)\")\n",
    "print(\"Test set:\")\n",
    "for sentiment in sorted(test_df['Sentiment'].unique()):\n",
    "    count = (test_df['Sentiment'] == sentiment).sum()\n",
    "    pct = round(count / len(test_df) * 100, 1)\n",
    "    print(f\"  {sentiment}: {count} ({pct}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ab5dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT PREPROCESSING AND TOKENIZATION\n",
      "\n",
      "Preprocessing training data...\n",
      "Preprocessing test data...\n",
      "Preprocessing complete!\n",
      "\n",
      "Sample preprocessed text:\n",
      "1. insufficient knowledge sql principle unable apply basic concept failed demonstrate basic dbms compet...\n",
      "2. satisfactory sql knowledge room improvement performance optimization fair dbms knowledge ability han...\n"
     ]
    }
   ],
   "source": [
    "print(\"TEXT PREPROCESSING AND TOKENIZATION\\n\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words and len(token) > 2]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "print(\"Preprocessing training data...\")\n",
    "train_df['processed_feedback'] = (train_df['Skill_Feedback_1'].fillna('') + ' ' + \n",
    "                                   train_df['Skill_Feedback_2'].fillna('') + ' ' + \n",
    "                                   train_df['Skill_Feedback_3'].fillna('') + ' ' + \n",
    "                                   train_df['Overall_Feedback'].fillna(''))\n",
    "train_df['processed_feedback'] = train_df['processed_feedback'].apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "test_df['processed_feedback'] = (test_df['Skill_Feedback_1'].fillna('') + ' ' + \n",
    "                                  test_df['Skill_Feedback_2'].fillna('') + ' ' + \n",
    "                                  test_df['Skill_Feedback_3'].fillna('') + ' ' + \n",
    "                                  test_df['Overall_Feedback'].fillna(''))\n",
    "test_df['processed_feedback'] = test_df['processed_feedback'].apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing complete!\")\n",
    "print(f\"\\nSample preprocessed text:\")\n",
    "for idx in range(2):\n",
    "    print(f\"{idx+1}. {train_df['processed_feedback'].iloc[idx][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "752f7b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILD NLP FEATURE EXTRACTION PIPELINE\n",
      "\n",
      "NLP Feature Extraction Complete:\n",
      "  Vocabulary size: 484\n",
      "  Max words (features): 5000\n",
      "  Training TF-IDF shape: (400, 484)\n",
      "  Test TF-IDF shape: (100, 484)\n",
      "  Target classes: ['negative', 'neutral', 'positive']\n",
      "  Training samples: 400\n",
      "  Test samples: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"BUILD NLP FEATURE EXTRACTION PIPELINE\\n\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "max_words = 5000\n",
    "max_length = 100\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_words, min_df=2, max_df=0.8, \n",
    "                                    ngram_range=(1, 2), lowercase=True, stop_words='english')\n",
    "\n",
    "X_train_tfidf_sparse = tfidf_vectorizer.fit_transform(train_df['processed_feedback'])\n",
    "X_test_tfidf_sparse = tfidf_vectorizer.transform(test_df['processed_feedback'])\n",
    "\n",
    "X_train_tfidf = X_train_tfidf_sparse.toarray().astype(np.float32)\n",
    "X_test_tfidf = X_test_tfidf_sparse.toarray().astype(np.float32)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(train_df['Sentiment'])\n",
    "y_test_encoded = le.transform(test_df['Sentiment'])\n",
    "\n",
    "print(\"NLP Feature Extraction Complete:\")\n",
    "print(f\"  Vocabulary size: {len(tfidf_vectorizer.get_feature_names_out())}\")\n",
    "print(f\"  Max words (features): {max_words}\")\n",
    "print(f\"  Training TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "print(f\"  Test TF-IDF shape: {X_test_tfidf.shape}\")\n",
    "print(f\"  Target classes: {list(le.classes_)}\")\n",
    "print(f\"  Training samples: {len(X_train_tfidf)}\")\n",
    "print(f\"  Test samples: {len(X_test_tfidf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20717a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN NLP-BASED CLASSIFICATION MODELS\n",
      "\n",
      "1. Logistic Regression (NLP)... 1.0000\n",
      "2. Random Forest (NLP)... 1.0000\n",
      "3. Gradient Boosting (NLP)... 1.0000\n",
      "\n",
      "NLP MODEL PERFORMANCE SUMMARY:\n",
      "  Logistic Regression: 1.0000 (100/100)\n",
      "  Random Forest: 1.0000 (100/100)\n",
      "  Gradient Boosting: 1.0000 (100/100)\n",
      "\n",
      "BEST NLP MODEL: Logistic Regression (1.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAIN NLP-BASED CLASSIFICATION MODELS\\n\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "models_nlp = {}\n",
    "results_nlp = {}\n",
    "\n",
    "print(\"1. Logistic Regression (NLP)...\", end=\" \", flush=True)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
    "lr_model.fit(X_train_tfidf, y_train_encoded)\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "acc_lr = accuracy_score(y_test_encoded, y_pred_lr)\n",
    "results_nlp['Logistic Regression'] = {'accuracy': acc_lr, 'predictions': y_pred_lr}\n",
    "models_nlp['Logistic Regression'] = lr_model\n",
    "print(f\"{acc_lr:.4f}\")\n",
    "\n",
    "print(\"2. Random Forest (NLP)...\", end=\" \", flush=True)\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, class_weight='balanced', max_depth=15)\n",
    "rf_model.fit(X_train_tfidf, y_train_encoded)\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "acc_rf = accuracy_score(y_test_encoded, y_pred_rf)\n",
    "results_nlp['Random Forest'] = {'accuracy': acc_rf, 'predictions': y_pred_rf}\n",
    "models_nlp['Random Forest'] = rf_model\n",
    "print(f\"{acc_rf:.4f}\")\n",
    "\n",
    "print(\"3. Gradient Boosting (NLP)...\", end=\" \", flush=True)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1, max_depth=5)\n",
    "gb_model.fit(X_train_tfidf, y_train_encoded)\n",
    "y_pred_gb = gb_model.predict(X_test_tfidf)\n",
    "acc_gb = accuracy_score(y_test_encoded, y_pred_gb)\n",
    "results_nlp['Gradient Boosting'] = {'accuracy': acc_gb, 'predictions': y_pred_gb}\n",
    "models_nlp['Gradient Boosting'] = gb_model\n",
    "print(f\"{acc_gb:.4f}\")\n",
    "\n",
    "print(\"\\nNLP MODEL PERFORMANCE SUMMARY:\")\n",
    "for model_name in sorted(results_nlp.keys(), key=lambda x: results_nlp[x]['accuracy'], reverse=True):\n",
    "    acc = results_nlp[model_name]['accuracy']\n",
    "    print(f\"  {model_name}: {acc:.4f} ({int(acc*len(y_test_encoded))}/{len(y_test_encoded)})\")\n",
    "\n",
    "best_nlp_model_name = max(results_nlp.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_nlp_model = models_nlp[best_nlp_model_name]\n",
    "best_nlp_predictions = results_nlp[best_nlp_model_name]['predictions']\n",
    "print(f\"\\nBEST NLP MODEL: {best_nlp_model_name} ({results_nlp[best_nlp_model_name]['accuracy']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eaab651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE MODEL PERFORMANCE WITH NLP METRICS\n",
      "\n",
      "OVERALL ACCURACY: 100.00% (100/100)\n",
      "\n",
      "ACCURACY BY SENTIMENT CLASS:\n",
      "  NEGATIVE: 21/21 (100.00%)\n",
      "  NEUTRAL: 34/34 (100.00%)\n",
      "  POSITIVE: 45/45 (100.00%)\n",
      "\n",
      "DETAILED NLP METRICS:\n",
      "  Precision (weighted): 1.0000\n",
      "  Recall (weighted): 1.0000\n",
      "  F1-Score (weighted): 1.0000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00        21\n",
      "     neutral       1.00      1.00      1.00        34\n",
      "    positive       1.00      1.00      1.00        45\n",
      "\n",
      "    accuracy                           1.00       100\n",
      "   macro avg       1.00      1.00      1.00       100\n",
      "weighted avg       1.00      1.00      1.00       100\n",
      "\n",
      "Predictions saved: nlp_model_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"EVALUATE MODEL PERFORMANCE WITH NLP METRICS\\n\")\n",
    "\n",
    "predictions_df = test_df.copy()\n",
    "predictions_df['Predicted_Sentiment'] = le.inverse_transform(best_nlp_predictions)\n",
    "predictions_df['True_Sentiment'] = test_df['Sentiment']\n",
    "predictions_df['Correct'] = predictions_df['Predicted_Sentiment'] == predictions_df['True_Sentiment']\n",
    "\n",
    "total_correct = predictions_df['Correct'].sum()\n",
    "total_records = len(predictions_df)\n",
    "overall_accuracy = total_correct / total_records\n",
    "\n",
    "print(f\"OVERALL ACCURACY: {overall_accuracy:.2%} ({total_correct}/{total_records})\\n\")\n",
    "\n",
    "print(\"ACCURACY BY SENTIMENT CLASS:\")\n",
    "for sentiment in le.classes_:\n",
    "    mask = predictions_df['True_Sentiment'] == sentiment\n",
    "    total = mask.sum()\n",
    "    correct = (predictions_df[mask]['Correct']).sum()\n",
    "    acc = correct / total if total > 0 else 0\n",
    "    print(f\"  {sentiment.upper()}: {correct}/{total} ({acc:.2%})\")\n",
    "\n",
    "print(\"\\nDETAILED NLP METRICS:\")\n",
    "precision = precision_score(y_test_encoded, best_nlp_predictions, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test_encoded, best_nlp_predictions, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test_encoded, best_nlp_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"  Precision (weighted): {precision:.4f}\")\n",
    "print(f\"  Recall (weighted): {recall:.4f}\")\n",
    "print(f\"  F1-Score (weighted): {f1:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_encoded, best_nlp_predictions, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "predictions_df.to_csv('nlp_model_predictions.csv', index=False)\n",
    "print(\"Predictions saved: nlp_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ac61873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE PREDICTIONS AND FEEDBACK WITH NLP\n",
      "\n",
      "Sample NLP-Generated Feedbacks:\n",
      "\n",
      "1. Rohan Chopra (positive): Ready for advancement. Demonstrates strong capabilities and readiness for growth.\n",
      "2. Kavya Reddy (neutral): Conditional progression. Shows promise but requires targeted development in identified areas.\n",
      "3. Kavya Desai (positive): Ready for advancement. Demonstrates strong capabilities and readiness for growth.\n",
      "4. Shreya Sharma (negative): Requires improvement. Needs additional support and training with mentorship.\n",
      "5. Shreya Singh (negative): Requires improvement. Needs additional support and training with mentorship.\n",
      "\n",
      "Final NLP CSV saved: nlp_final_feedback_with_all_columns.csv\n",
      "Total records: 100\n",
      "Columns: ['Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result', 'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback', 'Sentiment', 'Predicted_Sentiment', 'Final_Feedback']\n",
      "\n",
      "MODEL COMPARISON:\n",
      "Best NLP Model: Logistic Regression\n",
      "NLP Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"GENERATE PREDICTIONS AND FEEDBACK WITH NLP\\n\")\n",
    "\n",
    "def generate_nlp_feedback(predicted_sentiment):\n",
    "    if predicted_sentiment == 'positive':\n",
    "        return \"Ready for advancement. Demonstrates strong capabilities and readiness for growth.\"\n",
    "    elif predicted_sentiment == 'neutral':\n",
    "        return \"Conditional progression. Shows promise but requires targeted development in identified areas.\"\n",
    "    else:\n",
    "        return \"Requires improvement. Needs additional support and training with mentorship.\"\n",
    "\n",
    "predictions_df['Final_Feedback'] = predictions_df['Predicted_Sentiment'].apply(generate_nlp_feedback)\n",
    "\n",
    "print(\"Sample NLP-Generated Feedbacks:\\n\")\n",
    "for idx in range(min(5, len(predictions_df))):\n",
    "    print(f\"{idx+1}. {predictions_df['Associate_Name'].iloc[idx]} ({predictions_df['Predicted_Sentiment'].iloc[idx]}): {predictions_df['Final_Feedback'].iloc[idx]}\")\n",
    "\n",
    "final_nlp_df = predictions_df[[\n",
    "    'Employee_ID', 'Associate_Name', 'Department', 'Evaluation_Result',\n",
    "    'Skill_Feedback_1', 'Skill_Feedback_2', 'Skill_Feedback_3', 'Overall_Feedback',\n",
    "    'Sentiment', 'Predicted_Sentiment', 'Final_Feedback'\n",
    "]]\n",
    "\n",
    "final_nlp_df.to_csv('nlp_final_feedback_with_all_columns.csv', index=False)\n",
    "print(f\"\\nFinal NLP CSV saved: nlp_final_feedback_with_all_columns.csv\")\n",
    "print(f\"Total records: {len(final_nlp_df)}\")\n",
    "print(f\"Columns: {list(final_nlp_df.columns)}\")\n",
    "\n",
    "print(\"\\nMODEL COMPARISON:\")\n",
    "print(f\"Best NLP Model: {best_nlp_model_name}\")\n",
    "print(f\"NLP Model Accuracy: {overall_accuracy:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
