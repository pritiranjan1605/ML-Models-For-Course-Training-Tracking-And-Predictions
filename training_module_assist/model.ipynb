{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "40523dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "035a8f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Training: 402 records, 28 features\n",
      "Bench Employees: 109 records, 19 features\n",
      "Demands/Open Positions: 80 records, 12 features\n"
     ]
    }
   ],
   "source": [
    "# Load all datasets\n",
    "df = pd.read_csv('employee_training.csv')\n",
    "bench_df = pd.read_csv('bench_copy.csv')\n",
    "demands_df = pd.read_csv('demands.csv')\n",
    "\n",
    "print(f\"Employee Training: {df.shape[0]} records, {df.shape[1]} features\")\n",
    "print(f\"Bench Employees: {bench_df.shape[0]} records, {bench_df.shape[1]} features\")\n",
    "print(f\"Demands/Open Positions: {demands_df.shape[0]} records, {demands_df.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15cfb357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IN-DEMAND TECHNOLOGIES ===\n",
      "Technology\n",
      "Python           8\n",
      "ML               6\n",
      "Java             5\n",
      "AWS              5\n",
      "DevOps           4\n",
      "Spark            4\n",
      "Selenium         3\n",
      "Node.js          3\n",
      "React            3\n",
      "SQL              3\n",
      "JavaScript       2\n",
      "Cybersecurity    2\n",
      "Kubernetes       2\n",
      "Docker           2\n",
      "Azure            2\n",
      "CI/CD            2\n",
      "Kafka            2\n",
      "TensorFlow       2\n",
      "PyTorch          2\n",
      "Spring Boot      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total unique technologies in demand: 28\n",
      "Top 5 in-demand: ['Python', 'ML', 'Java', 'AWS', 'DevOps']\n"
     ]
    }
   ],
   "source": [
    "# Analyze demands to extract in-demand technologies\n",
    "in_demand_tech = demands_df['Technology'].value_counts()\n",
    "print(\"=== IN-DEMAND TECHNOLOGIES ===\")\n",
    "print(in_demand_tech.head(20))\n",
    "\n",
    "# Create a demand score dictionary (higher count = more demand)\n",
    "demand_scores = in_demand_tech.to_dict()\n",
    "max_demand = max(demand_scores.values()) if demand_scores else 1\n",
    "\n",
    "# Normalize demand scores (0-1)\n",
    "demand_scores_normalized = {tech: score/max_demand for tech, score in demand_scores.items()}\n",
    "\n",
    "print(f\"\\nTotal unique technologies in demand: {len(demand_scores)}\")\n",
    "print(f\"Top 5 in-demand: {list(demand_scores.keys())[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65882d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to 'Python': ['AI', 'Django', 'Spark', 'PyTorch', 'Databricks']\n",
      "Similar to 'Java': ['Spring Boot', 'Kafka', 'Android', 'Backend', 'Big Data']\n",
      "Similar to 'React': ['Frontend', 'Node.js', 'Next.js', 'Vue.js', 'Mobile']\n"
     ]
    }
   ],
   "source": [
    "# Define technology similarity mapping (technologies that are closely related)\n",
    "tech_similarity = {\n",
    "    # Programming Languages\n",
    "    'Python': ['Django', 'FastAPI', 'Flask', 'Pandas', 'ML', 'TensorFlow', 'PyTorch', 'Data Science'],\n",
    "    'Java': ['Spring Boot', 'Microservices', 'Kotlin', 'Android', 'Scala'],\n",
    "    'JavaScript': ['React', 'Angular', 'Vue.js', 'Node.js', 'TypeScript', 'Next.js'],\n",
    "    'TypeScript': ['Angular', 'React', 'Node.js', 'Next.js', 'JavaScript'],\n",
    "    'C++': ['Rust', 'Systems', 'Embedded Systems', 'Qt'],\n",
    "    'C#': ['.NET Core', 'Azure', '.NET', 'Blazor'],\n",
    "    'Go': ['Kubernetes', 'Docker', 'Microservices', 'Cloud'],\n",
    "    'Rust': ['WebAssembly', 'Systems', 'C++', 'Low Level'],\n",
    "    'Ruby': ['Rails', 'Full Stack'],\n",
    "    'PHP': ['Laravel', 'Web'],\n",
    "    'Scala': ['Spark', 'Big Data', 'Java', 'Kafka'],\n",
    "    \n",
    "    # Frontend\n",
    "    'React': ['JavaScript', 'TypeScript', 'Next.js', 'Redux', 'Frontend'],\n",
    "    'Angular': ['TypeScript', 'JavaScript', 'Frontend', 'RxJS'],\n",
    "    'Vue.js': ['JavaScript', 'Nuxt', 'Frontend'],\n",
    "    \n",
    "    # Backend & APIs\n",
    "    'Node.js': ['Express', 'JavaScript', 'TypeScript', 'GraphQL', 'Backend'],\n",
    "    'Django': ['Python', 'REST API', 'Backend'],\n",
    "    'FastAPI': ['Python', 'API', 'Backend', 'Microservices'],\n",
    "    'Spring Boot': ['Java', 'Microservices', 'Backend', 'REST API'],\n",
    "    'GraphQL': ['Node.js', 'API', 'Apollo'],\n",
    "    \n",
    "    # Cloud & DevOps\n",
    "    'AWS': ['Lambda', 'Cloud', 'Serverless', 'S3', 'EC2'],\n",
    "    'Azure': ['Cloud', 'C#', '.NET', 'DevOps'],\n",
    "    'Kubernetes': ['Docker', 'K8s', 'DevOps', 'Go', 'Cloud'],\n",
    "    'Docker': ['Kubernetes', 'DevOps', 'Containers', 'CI/CD'],\n",
    "    'Terraform': ['IaC', 'AWS', 'Azure', 'DevOps', 'Cloud'],\n",
    "    'CI/CD': ['Jenkins', 'DevOps', 'Docker', 'Kubernetes'],\n",
    "    \n",
    "    # Data & ML\n",
    "    'ML': ['Python', 'TensorFlow', 'PyTorch', 'Data Science', 'AI'],\n",
    "    'TensorFlow': ['ML', 'Python', 'Deep Learning', 'AI', 'PyTorch'],\n",
    "    'PyTorch': ['ML', 'Python', 'Deep Learning', 'AI', 'TensorFlow'],\n",
    "    'Spark': ['Scala', 'Python', 'Big Data', 'Databricks', 'Data Engineering'],\n",
    "    'SQL': ['PostgreSQL', 'MySQL', 'Oracle', 'Database', 'Data'],\n",
    "    'Snowflake': ['Data Warehouse', 'SQL', 'Cloud', 'ETL'],\n",
    "    'Kafka': ['Streaming', 'Data', 'Scala', 'Flink'],\n",
    "    \n",
    "    # Mobile\n",
    "    'iOS': ['Swift', 'Mobile', 'Apple'],\n",
    "    'Android': ['Kotlin', 'Java', 'Mobile'],\n",
    "    'Flutter': ['Dart', 'Mobile', 'Cross-platform'],\n",
    "    'React Native': ['React', 'JavaScript', 'Mobile'],\n",
    "    \n",
    "    # QA & Testing\n",
    "    'Selenium': ['Cypress', 'Automation', 'Testing', 'QA'],\n",
    "    'Cypress': ['Selenium', 'JavaScript', 'Testing', 'E2E'],\n",
    "    'Appium': ['Mobile Testing', 'Automation', 'QA'],\n",
    "    'JMeter': ['Performance', 'Load Testing', 'Gatling'],\n",
    "    \n",
    "    # Security & Others\n",
    "    'Cybersecurity': ['OWASP', 'Security', 'Penetration Testing'],\n",
    "    'Blockchain': ['Solidity', 'Ethereum', 'Smart Contracts', 'Web3'],\n",
    "    'Solidity': ['Blockchain', 'Ethereum', 'Smart Contracts'],\n",
    "}\n",
    "\n",
    "# Create reverse mapping for quick lookup\n",
    "def get_similar_techs(tech):\n",
    "    \"\"\"Get list of similar technologies for a given tech\"\"\"\n",
    "    similar = set()\n",
    "    tech_upper = tech.strip()\n",
    "    \n",
    "    # Direct matches\n",
    "    if tech_upper in tech_similarity:\n",
    "        similar.update(tech_similarity[tech_upper])\n",
    "    \n",
    "    # Reverse lookup - find techs that list this one as similar\n",
    "    for key, values in tech_similarity.items():\n",
    "        if tech_upper in values or tech_upper.lower() in [v.lower() for v in values]:\n",
    "            similar.add(key)\n",
    "            similar.update(values)\n",
    "    \n",
    "    similar.discard(tech_upper)\n",
    "    return list(similar)\n",
    "\n",
    "# Test similarity mapping\n",
    "print(\"Similar to 'Python':\", get_similar_techs('Python')[:5])\n",
    "print(\"Similar to 'Java':\", get_similar_techs('Java')[:5])\n",
    "print(\"Similar to 'React':\", get_similar_techs('React')[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8dee566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BENCH EMPLOYEES SKILL-DEMAND ANALYSIS ===\n",
      "\n",
      "          Name   Primary_Skill Demand_Status                    Recommendation\n",
      "   Daniel Park            Java     IN DEMAND       Continue with Java training\n",
      "   George Wang      JavaScript     IN DEMAND Continue with JavaScript training\n",
      " Kevin O'Brien            Java     IN DEMAND       Continue with Java training\n",
      "Oscar Martinez           Linux     IN DEMAND      Continue with Linux training\n",
      "  Rachel Green              Go     IN DEMAND         Continue with Go training\n",
      "   Xavier Ross         Windows NOT IN DEMAND     Explore trending technologies\n",
      " Brandon Scott          Appium NOT IN DEMAND     Explore trending technologies\n",
      "   Henry Adams         Tableau NOT IN DEMAND     Explore trending technologies\n",
      " Maria Johnson        Cucumber NOT IN DEMAND     Explore trending technologies\n",
      "   Rita Wilson Robot Framework NOT IN DEMAND     Explore trending technologies\n",
      "  Xena Warrior         Haskell NOT IN DEMAND     Explore trending technologies\n",
      "  Diana Prince       Snowflake NOT IN DEMAND       Consider upskilling to: SQL\n",
      " Julia Roberts            Okta NOT IN DEMAND     Explore trending technologies\n",
      "  Priya Sharma          Blazor NOT IN DEMAND     Consider upskilling to: Azure\n",
      "   Xander Cage             H2O NOT IN DEMAND     Explore trending technologies\n"
     ]
    }
   ],
   "source": [
    "# Map bench employees with training data and analyze demand status\n",
    "def check_demand_status(skill):\n",
    "    \"\"\"Check if a skill is in demand and return demand score\"\"\"\n",
    "    skill_clean = str(skill).strip()\n",
    "    \n",
    "    # Direct match\n",
    "    if skill_clean in demand_scores:\n",
    "        return True, demand_scores[skill_clean], skill_clean\n",
    "    \n",
    "    # Case-insensitive match\n",
    "    for tech in demand_scores.keys():\n",
    "        if skill_clean.lower() == tech.lower():\n",
    "            return True, demand_scores[tech], tech\n",
    "    \n",
    "    return False, 0, None\n",
    "\n",
    "def find_closest_in_demand_tech(current_skill):\n",
    "    \"\"\"Find the closest technology that is in demand\"\"\"\n",
    "    similar_techs = get_similar_techs(current_skill)\n",
    "    \n",
    "    # Score similar techs by demand\n",
    "    in_demand_similar = []\n",
    "    for tech in similar_techs:\n",
    "        is_in_demand, score, matched_tech = check_demand_status(tech)\n",
    "        if is_in_demand:\n",
    "            in_demand_similar.append((matched_tech, score))\n",
    "    \n",
    "    # Sort by demand score (highest first)\n",
    "    in_demand_similar.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return in_demand_similar\n",
    "\n",
    "# Merge bench data with training data\n",
    "# First, let's standardize column names\n",
    "bench_df_clean = bench_df.copy()\n",
    "bench_df_clean = bench_df_clean.rename(columns={\n",
    "    'Emp Id': 'Emp_Id',\n",
    "    'Associate': 'Employee_Name',\n",
    "    'Primary Skill': 'Primary_Skill',\n",
    "    'Current_Skill': 'Secondary_Skill',\n",
    "    'Work City': 'Location',\n",
    "    'Line_Manager': 'Manager'\n",
    "})\n",
    "\n",
    "# Analyze bench employees' skills vs demand\n",
    "print(\"=== BENCH EMPLOYEES SKILL-DEMAND ANALYSIS ===\\n\")\n",
    "\n",
    "bench_analysis = []\n",
    "for _, emp in bench_df_clean.iterrows():\n",
    "    emp_id = emp['Emp_Id']\n",
    "    name = emp['Employee_Name']\n",
    "    primary_skill = emp['Primary_Skill']\n",
    "    current_skill = emp.get('Secondary_Skill', primary_skill)\n",
    "    \n",
    "    # Check if primary skill is in demand\n",
    "    is_in_demand, demand_score, matched = check_demand_status(primary_skill)\n",
    "    \n",
    "    if is_in_demand:\n",
    "        status = \"IN DEMAND\"\n",
    "        recommendation = f\"Continue with {primary_skill} training\"\n",
    "        alt_techs = []\n",
    "    else:\n",
    "        status = \"NOT IN DEMAND\"\n",
    "        alt_techs = find_closest_in_demand_tech(primary_skill)\n",
    "        if alt_techs:\n",
    "            recommendation = f\"Consider upskilling to: {', '.join([t[0] for t in alt_techs[:3]])}\"\n",
    "        else:\n",
    "            recommendation = \"Explore trending technologies\"\n",
    "    \n",
    "    bench_analysis.append({\n",
    "        'Emp_Id': emp_id,\n",
    "        'Name': name,\n",
    "        'Primary_Skill': primary_skill,\n",
    "        'Demand_Status': status,\n",
    "        'Demand_Score': demand_score,\n",
    "        'Recommendation': recommendation,\n",
    "        'Alternative_Techs': alt_techs[:3] if not is_in_demand else []\n",
    "    })\n",
    "\n",
    "bench_analysis_df = pd.DataFrame(bench_analysis)\n",
    "print(bench_analysis_df[['Name', 'Primary_Skill', 'Demand_Status', 'Recommendation']].head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "48112028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ENHANCED DATASET WITH DEMAND FEATURES ===\n",
      "Total records: 402\n",
      "\n",
      "Demand feature distribution:\n",
      "  - Primary skills in demand: 279\n",
      "  - Primary skills not in demand: 123\n",
      "\n",
      "Skill-Course Mapping Test:\n",
      "  - Python courses: ['Machine Learning with Python', 'Data Analysis and Visualization', 'Data Pipeline Engineering', 'Python Programming Fundamentals']\n",
      "  - Java courses: ['Backend API Development', 'Software Architecture Design', 'Full Stack Web Development']\n",
      "\n",
      "Sample of enhanced data:\n",
      " Employee_Name   Primary_Skill  Primary_Skill_In_Demand                     Course_Name\n",
      "   Daniel Park            Java                        1         Backend API Development\n",
      "   George Wang      JavaScript                        1      Full Stack Web Development\n",
      "  Kevin OBrien            Java                        1    Software Architecture Design\n",
      "Oscar Martinez           Linux                        1     Linux System Administration\n",
      "  Rachel Green              Go                        1       DevOps and CI/CD Pipeline\n",
      "   Xavier Ross         Windows                        0          AWS Cloud Practitioner\n",
      " Brandon Scott          Appium                        0 Automated Testing with Selenium\n",
      "   Henry Adams         Tableau                        0    Machine Learning with Python\n",
      " Maria Johnson        Cucumber                        0 Automated Testing with Selenium\n",
      "   Rita Wilson Robot Framework                        0 Python Programming Fundamentals\n"
     ]
    }
   ],
   "source": [
    "# Create enhanced training dataset by merging employee_training with bench data\n",
    "# Add demand-aware features\n",
    "\n",
    "# Merge training data with bench data where possible\n",
    "merged_df = df.copy()\n",
    "\n",
    "# Add demand score for primary skill\n",
    "merged_df['Primary_Skill_In_Demand'] = merged_df['Primary_Skill'].apply(\n",
    "    lambda x: 1 if check_demand_status(x)[0] else 0\n",
    ")\n",
    "merged_df['Primary_Skill_Demand_Score'] = merged_df['Primary_Skill'].apply(\n",
    "    lambda x: check_demand_status(x)[1]\n",
    ")\n",
    "\n",
    "# Add demand score for secondary skill\n",
    "merged_df['Secondary_Skill_In_Demand'] = merged_df['Secondary_Skill'].apply(\n",
    "    lambda x: 1 if check_demand_status(x)[0] else 0\n",
    ")\n",
    "merged_df['Secondary_Skill_Demand_Score'] = merged_df['Secondary_Skill'].apply(\n",
    "    lambda x: check_demand_status(x)[1]\n",
    ")\n",
    "\n",
    "# Enhanced mapping of courses to target technologies AND related skills\n",
    "course_to_tech_map = {\n",
    "    'Python Programming Fundamentals': 'Python',\n",
    "    'Machine Learning with Python': 'ML',\n",
    "    'Data Analysis and Visualization': 'SQL',\n",
    "    'Full Stack Web Development': 'JavaScript',\n",
    "    'DevOps and CI/CD Pipeline': 'CI/CD',\n",
    "    'AWS Cloud Practitioner': 'AWS',\n",
    "    'Backend API Development': 'Node.js',\n",
    "    'Automated Testing with Selenium': 'Selenium',\n",
    "    'Data Pipeline Engineering': 'Spark',\n",
    "    'Cybersecurity Essentials': 'Cybersecurity',\n",
    "    'Software Architecture Design': 'Microservices',\n",
    "    'Agile Project Management': 'Agile',\n",
    "    'Linux System Administration': 'Linux',\n",
    "}\n",
    "\n",
    "# CRITICAL: Skill-to-Course relevance mapping (which courses are relevant for which skills)\n",
    "skill_to_courses_map = {\n",
    "    'Python': ['Machine Learning with Python', 'Data Analysis and Visualization', 'Data Pipeline Engineering', 'Python Programming Fundamentals'],\n",
    "    'ML': ['Machine Learning with Python', 'Data Analysis and Visualization', 'Data Pipeline Engineering'],\n",
    "    'Data Science': ['Machine Learning with Python', 'Data Analysis and Visualization', 'Data Pipeline Engineering'],\n",
    "    'TensorFlow': ['Machine Learning with Python', 'Data Pipeline Engineering'],\n",
    "    'PyTorch': ['Machine Learning with Python', 'Data Pipeline Engineering'],\n",
    "    'Pandas': ['Data Analysis and Visualization', 'Machine Learning with Python'],\n",
    "    'Java': ['Backend API Development', 'Software Architecture Design', 'Full Stack Web Development'],\n",
    "    'Spring Boot': ['Backend API Development', 'Software Architecture Design'],\n",
    "    'JavaScript': ['Full Stack Web Development', 'Backend API Development'],\n",
    "    'React': ['Full Stack Web Development'],\n",
    "    'Angular': ['Full Stack Web Development'],\n",
    "    'Node.js': ['Backend API Development', 'Full Stack Web Development'],\n",
    "    'TypeScript': ['Full Stack Web Development', 'Backend API Development'],\n",
    "    'AWS': ['AWS Cloud Practitioner', 'DevOps and CI/CD Pipeline'],\n",
    "    'Azure': ['AWS Cloud Practitioner', 'DevOps and CI/CD Pipeline'],\n",
    "    'Docker': ['DevOps and CI/CD Pipeline', 'AWS Cloud Practitioner'],\n",
    "    'Kubernetes': ['DevOps and CI/CD Pipeline', 'AWS Cloud Practitioner'],\n",
    "    'CI/CD': ['DevOps and CI/CD Pipeline'],\n",
    "    'DevOps': ['DevOps and CI/CD Pipeline', 'AWS Cloud Practitioner', 'Linux System Administration'],\n",
    "    'SQL': ['Data Analysis and Visualization', 'Data Pipeline Engineering'],\n",
    "    'Spark': ['Data Pipeline Engineering', 'Data Analysis and Visualization'],\n",
    "    'Selenium': ['Automated Testing with Selenium'],\n",
    "    'QA': ['Automated Testing with Selenium'],\n",
    "    'Testing': ['Automated Testing with Selenium'],\n",
    "    'Cybersecurity': ['Cybersecurity Essentials'],\n",
    "    'Security': ['Cybersecurity Essentials'],\n",
    "    'Linux': ['Linux System Administration', 'DevOps and CI/CD Pipeline'],\n",
    "    'Agile': ['Agile Project Management', 'Software Architecture Design'],\n",
    "    'Microservices': ['Software Architecture Design', 'Backend API Development'],\n",
    "    '.NET': ['Backend API Development', 'Full Stack Web Development'],\n",
    "    'C#': ['Backend API Development', 'Full Stack Web Development'],\n",
    "}\n",
    "\n",
    "# Function to get relevant courses for a skill\n",
    "def get_relevant_courses_for_skill(skill):\n",
    "    \"\"\"Get list of courses relevant to a skill\"\"\"\n",
    "    skill_clean = str(skill).strip()\n",
    "    \n",
    "    # Direct match\n",
    "    if skill_clean in skill_to_courses_map:\n",
    "        return skill_to_courses_map[skill_clean]\n",
    "    \n",
    "    # Case-insensitive match\n",
    "    for s, courses in skill_to_courses_map.items():\n",
    "        if skill_clean.lower() == s.lower():\n",
    "            return courses\n",
    "    \n",
    "    # Check similar technologies\n",
    "    similar_techs = get_similar_techs(skill_clean)\n",
    "    for tech in similar_techs:\n",
    "        if tech in skill_to_courses_map:\n",
    "            return skill_to_courses_map[tech]\n",
    "    \n",
    "    return []\n",
    "\n",
    "# Add course target technology demand\n",
    "merged_df['Course_Tech'] = merged_df['Course_Name'].map(course_to_tech_map).fillna('Unknown')\n",
    "merged_df['Course_Tech_In_Demand'] = merged_df['Course_Tech'].apply(\n",
    "    lambda x: 1 if check_demand_status(x)[0] else 0\n",
    ")\n",
    "\n",
    "print(\"=== ENHANCED DATASET WITH DEMAND FEATURES ===\")\n",
    "print(f\"Total records: {len(merged_df)}\")\n",
    "print(f\"\\nDemand feature distribution:\")\n",
    "print(f\"  - Primary skills in demand: {merged_df['Primary_Skill_In_Demand'].sum()}\")\n",
    "print(f\"  - Primary skills not in demand: {(merged_df['Primary_Skill_In_Demand'] == 0).sum()}\")\n",
    "print(f\"\\nSkill-Course Mapping Test:\")\n",
    "print(f\"  - Python courses: {get_relevant_courses_for_skill('Python')}\")\n",
    "print(f\"  - Java courses: {get_relevant_courses_for_skill('Java')}\")\n",
    "print(f\"\\nSample of enhanced data:\")\n",
    "print(merged_df[['Employee_Name', 'Primary_Skill', 'Primary_Skill_In_Demand', 'Course_Name']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "108db1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course_Category\n",
      "Analytics           1\n",
      "Architecture        1\n",
      "Backend             1\n",
      "Cloud               1\n",
      "Data Engineering    1\n",
      "Data Science        1\n",
      "DevOps              1\n",
      "Development         1\n",
      "Infrastructure      1\n",
      "Management          1\n",
      "Programming         1\n",
      "Security            1\n",
      "Testing             1\n",
      "Unknown             1\n",
      "Name: Course_Name, dtype: int64\n",
      "\n",
      "Prepared dataset with 14 unique training modules\n",
      "New demand-aware features added: Primary_Skill_In_Demand, Demand_Gap_Interaction\n"
     ]
    }
   ],
   "source": [
    "# Use enhanced merged dataframe with demand features\n",
    "data = merged_df.copy()\n",
    "\n",
    "# Fill missing values for key training features\n",
    "data['Grade'] = data['Grade'].fillna('G1')\n",
    "data['Department'] = data['Department'].fillna('Unknown')\n",
    "data['Primary_Skill'] = data['Primary_Skill'].fillna('Unknown')\n",
    "data['Secondary_Skill'] = data['Secondary_Skill'].fillna('Unknown')\n",
    "data['Course_Category'] = data['Course_Category'].fillna('Unknown')\n",
    "data['Business_Priority'] = data['Business_Priority'].fillna('Medium')\n",
    "data['Career_Goal'] = data['Career_Goal'].fillna('Unknown')\n",
    "data['Course_Name'] = data['Course_Name'].fillna('Unknown Course')\n",
    "\n",
    "# Derive numeric grade features\n",
    "data['Grade_Num'] = data['Grade'].str.extract(\"(\\d+)\").astype(int)\n",
    "experience_map = {1: 0, 2: 0.5, 3: 1.5, 4: 3, 5: 5, 6: 7, 7: 10, 8: 12, 9: 15, 10: 18}\n",
    "data['Experience_Level'] = data['Grade_Num'].map(experience_map).fillna(0)\n",
    "\n",
    "# Add Skill_Gap_Score and Performance_Rating if available\n",
    "if 'Skill_Gap_Score' in data.columns:\n",
    "    data['Skill_Gap_Score'] = data['Skill_Gap_Score'].fillna(data['Skill_Gap_Score'].median())\n",
    "else:\n",
    "    data['Skill_Gap_Score'] = 0.3\n",
    "\n",
    "if 'Performance_Rating' in data.columns:\n",
    "    data['Performance_Rating'] = data['Performance_Rating'].fillna(data['Performance_Rating'].median())\n",
    "else:\n",
    "    data['Performance_Rating'] = 4.0\n",
    "\n",
    "# Normalize demand scores\n",
    "max_demand_score = data['Primary_Skill_Demand_Score'].max() if data['Primary_Skill_Demand_Score'].max() > 0 else 1\n",
    "data['Primary_Skill_Demand_Normalized'] = data['Primary_Skill_Demand_Score'] / max_demand_score\n",
    "data['Secondary_Skill_Demand_Normalized'] = data['Secondary_Skill_Demand_Score'] / max_demand_score\n",
    "\n",
    "# Create interaction features\n",
    "data['Grade_Skill_Interaction'] = data['Grade_Num'] * data['Skill_Gap_Score']\n",
    "data['Grade_Performance'] = data['Grade_Num'] * data['Performance_Rating']\n",
    "data['Demand_Gap_Interaction'] = data['Primary_Skill_In_Demand'] * data['Skill_Gap_Score']\n",
    "\n",
    "# Encode all categorical features for training\n",
    "label_encoders = {}\n",
    "for col in ['Department', 'Primary_Skill', 'Secondary_Skill', 'Course_Category', 'Business_Priority', 'Career_Goal']:\n",
    "    values = pd.concat([data[col].astype(str), pd.Series(['Unknown'])], ignore_index=True)\n",
    "    le = LabelEncoder()\n",
    "    le.fit(values)\n",
    "    data[f'{col}_Encoded'] = le.transform(data[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Encode the target course name\n",
    "target_encoder = LabelEncoder()\n",
    "data['Target'] = target_encoder.fit_transform(data['Course_Name'].astype(str))\n",
    "\n",
    "# Store reference catalog\n",
    "course_catalog = data[['Course_Name', 'Course_Category']].drop_duplicates()\n",
    "print(data.groupby('Course_Category')['Course_Name'].nunique())\n",
    "\n",
    "print(f\"\\nPrepared dataset with {data['Target'].nunique()} unique training modules\")\n",
    "print(f\"New demand-aware features added: Primary_Skill_In_Demand, Demand_Gap_Interaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37627514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 321 rows | Test set: 81 rows\n",
      "Unique courses in training: 14\n",
      "Total features: 16 (including 4 new demand features)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature columns with expanded attributes INCLUDING DEMAND FEATURES\n",
    "feature_cols = [\n",
    "    'Grade_Num',\n",
    "    'Experience_Level',\n",
    "    'Department_Encoded',\n",
    "    'Primary_Skill_Encoded',\n",
    "    'Secondary_Skill_Encoded',\n",
    "    'Course_Category_Encoded',\n",
    "    'Business_Priority_Encoded',\n",
    "    'Career_Goal_Encoded',\n",
    "    'Skill_Gap_Score',\n",
    "    'Performance_Rating',\n",
    "    'Grade_Skill_Interaction',\n",
    "    'Grade_Performance',\n",
    "    # New demand-aware features\n",
    "    'Primary_Skill_In_Demand',\n",
    "    'Primary_Skill_Demand_Normalized',\n",
    "    'Secondary_Skill_In_Demand',\n",
    "    'Demand_Gap_Interaction'\n",
    "]\n",
    "\n",
    "# Train-test split\n",
    "X, y = data[feature_cols], data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features for better performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Train set: {X_train.shape[0]} rows | Test set: {X_test.shape[0]} rows\")\n",
    "print(f\"Unique courses in training: {y_train.nunique()}\")\n",
    "print(f\"Total features: {len(feature_cols)} (including 4 new demand features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2e3c7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original courses: 14\n",
      "Filtered courses (≥2 samples): 14\n",
      "Removed 0 courses with single samples\n",
      "\n",
      "Train set: 321 rows\n",
      "Test set: 81 rows\n",
      "Train Accuracy: 99.4%\n",
      "Test Accuracy: 96.3%\n",
      "Overfitting Gap: 3.1%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Filter out courses with only 1 sample (can't stratify with single samples)\n",
    "course_counts = data['Course_Name'].value_counts()\n",
    "valid_courses = course_counts[course_counts >= 2].index\n",
    "data_filtered = data[data['Course_Name'].isin(valid_courses)].copy()\n",
    "\n",
    "print(f\"Original courses: {data['Course_Name'].nunique()}\")\n",
    "print(f\"Filtered courses (≥2 samples): {data_filtered['Course_Name'].nunique()}\")\n",
    "print(f\"Removed {data['Course_Name'].nunique() - data_filtered['Course_Name'].nunique()} courses with single samples\")\n",
    "\n",
    "# Re-encode target with filtered data\n",
    "target_encoder = LabelEncoder()\n",
    "data_filtered['Target'] = target_encoder.fit_transform(data_filtered['Course_Name'].astype(str))\n",
    "\n",
    "# Update course catalog with filtered data\n",
    "course_catalog = data_filtered[['Course_Name', 'Course_Category']].drop_duplicates()\n",
    "\n",
    "# Update X and y with filtered data\n",
    "X_filtered = data_filtered[feature_cols]\n",
    "y_filtered = data_filtered['Target']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set: {X_test.shape[0]} rows\")\n",
    "\n",
    "\n",
    "# XGBoost optimized for better accuracy with sufficient data\n",
    "model = XGBClassifier(\n",
    "    n_estimators=800,          # More trees for better learning\n",
    "    max_depth=6,               # Deeper trees now that we have more data\n",
    "    learning_rate=0.05,        # Lower learning rate for better convergence\n",
    "    subsample=0.85,            # Use 85% of data per tree\n",
    "    colsample_bytree=0.85,     # Use 85% of features per tree\n",
    "    min_child_weight=2,        # Require 2 samples per leaf\n",
    "    gamma=0.2,                 # Moderate regularization\n",
    "    reg_alpha=0.5,             # L1 regularization\n",
    "    reg_lambda=1.5,            # L2 regularization\n",
    "    scale_pos_weight=1,        \n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    eval_metric='mlogloss',\n",
    "    early_stopping_rounds=50\n",
    ")\n",
    "\n",
    "# Train with evaluation set for early stopping\n",
    "eval_set = [(X_train_scaled, y_train), (X_test_scaled, y_test)]\n",
    "model.fit(X_train_scaled, y_train, eval_set=eval_set, verbose=False)\n",
    "\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "test_acc = accuracy_score(y_test, test_predictions)\n",
    "train_acc = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "\n",
    "print(f\"Train Accuracy: {train_acc:.1%}\")\n",
    "print(f\"Test Accuracy: {test_acc:.1%}\")\n",
    "print(f\"Overfitting Gap: {(train_acc - test_acc):.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "208385ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced DEMAND-AWARE recommendation function with skill-course relevance\n",
    "def recommend_course_demand_aware(employee, top_n=3, consider_demand=True):\n",
    "    \"\"\"\n",
    "    Recommend courses considering:\n",
    "    1. Check if employee's skill has ACTIVE DEMAND in requirements\n",
    "    2. If IN DEMAND - suggest courses relevant to that skill (ML for Python, etc.)\n",
    "    3. If NOT IN DEMAND - suggest pivot to in-demand tech and relevant courses\n",
    "    \"\"\"\n",
    "    grade_value = str(employee.get('Grade', 'G3'))\n",
    "    digits = ''.join(ch for ch in grade_value if ch.isdigit())\n",
    "    grade_num = int(digits) if digits else 3\n",
    "    \n",
    "    skill_gap = employee.get('Skill_Gap_Score', 0.3)\n",
    "    performance = employee.get('Performance_Rating', 4.0)\n",
    "    primary_skill = employee.get('Primary_Skill', 'Unknown')\n",
    "    secondary_skill = employee.get('Secondary_Skill', primary_skill)\n",
    "    \n",
    "    # Check demand status for employee's primary skill\n",
    "    is_in_demand, demand_score, matched_tech = check_demand_status(primary_skill)\n",
    "    \n",
    "    # Also check if related skills are in demand (e.g., ML demand for Python developer)\n",
    "    related_demand = []\n",
    "    similar_techs = get_similar_techs(primary_skill)\n",
    "    for tech in similar_techs:\n",
    "        tech_in_demand, tech_score, _ = check_demand_status(tech)\n",
    "        if tech_in_demand:\n",
    "            related_demand.append((tech, tech_score))\n",
    "    related_demand.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Prepare demand analysis\n",
    "    demand_analysis = {\n",
    "        'Primary_Skill': primary_skill,\n",
    "        'Is_In_Demand': is_in_demand,\n",
    "        'Demand_Score': demand_score,\n",
    "        'Related_In_Demand': related_demand[:3],\n",
    "        'Alternative_Techs': []\n",
    "    }\n",
    "    \n",
    "    # Determine recommendation strategy\n",
    "    recommended_skill = primary_skill\n",
    "    need_pivot = False\n",
    "    \n",
    "    if is_in_demand:\n",
    "        # Skill is in demand - recommend courses for this skill\n",
    "        demand_analysis['Strategy'] = 'SKILL_IN_DEMAND'\n",
    "    elif related_demand:\n",
    "        # Skill not directly in demand, but related skills are (e.g., Python -> ML)\n",
    "        demand_analysis['Strategy'] = 'RELATED_DEMAND'\n",
    "        demand_analysis['Related_Tech_Focus'] = related_demand[0][0]\n",
    "    else:\n",
    "        # No demand for skill or related - suggest pivot\n",
    "        need_pivot = True\n",
    "        alt_techs = find_closest_in_demand_tech(primary_skill)\n",
    "        demand_analysis['Alternative_Techs'] = alt_techs[:3]\n",
    "        demand_analysis['Strategy'] = 'NEED_PIVOT'\n",
    "        if alt_techs:\n",
    "            recommended_skill = alt_techs[0][0]\n",
    "            demand_analysis['Recommended_Pivot'] = recommended_skill\n",
    "    \n",
    "    # Get relevant courses for the PRIMARY skill FIRST (most important)\n",
    "    relevant_courses = get_relevant_courses_for_skill(primary_skill if not need_pivot else recommended_skill)\n",
    "    \n",
    "    # Calculate demand features for ML model\n",
    "    rec_in_demand, rec_demand_score, _ = check_demand_status(recommended_skill)\n",
    "    max_demand = max(demand_scores.values()) if demand_scores else 1\n",
    "    \n",
    "    profile = {\n",
    "        'Grade_Num': grade_num,\n",
    "        'Experience_Level': experience_map.get(grade_num, 0.0),\n",
    "        'Skill_Gap_Score': skill_gap,\n",
    "        'Performance_Rating': performance,\n",
    "        'Grade_Skill_Interaction': grade_num * skill_gap,\n",
    "        'Grade_Performance': grade_num * performance,\n",
    "        'Primary_Skill_In_Demand': 1 if (is_in_demand or related_demand) else 0,\n",
    "        'Primary_Skill_Demand_Normalized': rec_demand_score / max_demand if max_demand > 0 else 0,\n",
    "        'Secondary_Skill_In_Demand': 1 if check_demand_status(secondary_skill)[0] else 0,\n",
    "        'Demand_Gap_Interaction': (1 if (is_in_demand or related_demand) else 0) * skill_gap\n",
    "    }\n",
    "\n",
    "    for col in ['Department', 'Primary_Skill', 'Secondary_Skill', 'Course_Category', 'Business_Priority', 'Career_Goal']:\n",
    "        encoder = label_encoders[col]\n",
    "        if col == 'Primary_Skill' and need_pivot and consider_demand:\n",
    "            value = recommended_skill\n",
    "        else:\n",
    "            value = str(employee.get(col, 'Unknown') or 'Unknown')\n",
    "        \n",
    "        if value not in encoder.classes_:\n",
    "            value = 'Unknown'\n",
    "        profile[f'{col}_Encoded'] = int(encoder.transform([value])[0])\n",
    "\n",
    "    X_new = pd.DataFrame([profile])[feature_cols]\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "\n",
    "    # Get ML model probabilities\n",
    "    probabilities = model.predict_proba(X_new_scaled)[0]\n",
    "    \n",
    "    # SMART RECOMMENDATION: Prioritize SKILL-RELEVANT courses when skill is in demand\n",
    "    recommendations = []\n",
    "    \n",
    "    if (is_in_demand or related_demand) and relevant_courses:\n",
    "        # SKILL IS IN DEMAND: Return skill-relevant courses directly (ordered by relevance)\n",
    "        for i, course in enumerate(relevant_courses[:top_n]):\n",
    "            if course in target_encoder.classes_:\n",
    "                idx = target_encoder.transform([course])[0]\n",
    "                base_confidence = probabilities[idx]\n",
    "                catalog_row = course_catalog[course_catalog['Course_Name'] == course]\n",
    "                course_category = catalog_row['Course_Category'].iloc[0] if not catalog_row.empty else 'Unknown'\n",
    "                course_tech = course_to_tech_map.get(course, 'General')\n",
    "                course_in_demand = check_demand_status(course_tech)[0]\n",
    "                \n",
    "                # Strong boost for skill-relevant courses (descending priority)\n",
    "                relevance_boost = 0.95 - (i * 0.15)  # First: 95%, Second: 80%, Third: 65%\n",
    "                boosted_confidence = max(relevance_boost, base_confidence)\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'Course_Name': course,\n",
    "                    'Course_Category': course_category,\n",
    "                    'Confidence': boosted_confidence,\n",
    "                    'Target_Technology': course_tech,\n",
    "                    'Tech_In_Demand': course_in_demand,\n",
    "                    'Relevance': 'HIGH'\n",
    "                })\n",
    "    else:\n",
    "        # SKILL NOT IN DEMAND: Use ML model predictions but filter for relevant courses if available\n",
    "        top_indices = np.argsort(probabilities)[::-1]\n",
    "        \n",
    "        # First try to add relevant courses for pivot skill\n",
    "        if relevant_courses:\n",
    "            for course in relevant_courses[:top_n]:\n",
    "                if course in target_encoder.classes_:\n",
    "                    idx = target_encoder.transform([course])[0]\n",
    "                    confidence = probabilities[idx]\n",
    "                    catalog_row = course_catalog[course_catalog['Course_Name'] == course]\n",
    "                    course_category = catalog_row['Course_Category'].iloc[0] if not catalog_row.empty else 'Unknown'\n",
    "                    course_tech = course_to_tech_map.get(course, 'General')\n",
    "                    course_in_demand = check_demand_status(course_tech)[0]\n",
    "                    \n",
    "                    recommendations.append({\n",
    "                        'Course_Name': course,\n",
    "                        'Course_Category': course_category,\n",
    "                        'Confidence': confidence,\n",
    "                        'Target_Technology': course_tech,\n",
    "                        'Tech_In_Demand': course_in_demand,\n",
    "                        'Relevance': 'PIVOT'\n",
    "                    })\n",
    "        \n",
    "        # Add from ML model if needed\n",
    "        for idx in top_indices:\n",
    "            if len(recommendations) >= top_n:\n",
    "                break\n",
    "            course_name = target_encoder.inverse_transform([idx])[0]\n",
    "            if course_name not in [r['Course_Name'] for r in recommendations]:\n",
    "                confidence = probabilities[idx]\n",
    "                catalog_row = course_catalog[course_catalog['Course_Name'] == course_name]\n",
    "                course_category = catalog_row['Course_Category'].iloc[0] if not catalog_row.empty else 'Unknown'\n",
    "                course_tech = course_to_tech_map.get(course_name, 'General')\n",
    "                course_in_demand = check_demand_status(course_tech)[0]\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'Course_Name': course_name,\n",
    "                    'Course_Category': course_category,\n",
    "                    'Confidence': confidence,\n",
    "                    'Target_Technology': course_tech,\n",
    "                    'Tech_In_Demand': course_in_demand,\n",
    "                    'Relevance': 'ML_PREDICTED'\n",
    "                })\n",
    "    \n",
    "    # Sort by confidence and take top_n\n",
    "    recommendations.sort(key=lambda x: x['Confidence'], reverse=True)\n",
    "    \n",
    "    return recommendations[:top_n], demand_analysis\n",
    "\n",
    "# Legacy wrapper for backward compatibility\n",
    "def recommend_course(employee, top_n=3):\n",
    "    recs, _ = recommend_course_demand_aware(employee, top_n, consider_demand=False)\n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ebc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEMAND-AWARE COURSE RECOMMENDATION SYSTEM\n",
      "============================================================\n",
      "\n",
      ">>> TEST 1: Employee with IN-DEMAND skill (Python)\n",
      "Profile: Python developer, G5\n",
      "\n",
      "Demand Analysis:\n",
      "   - Current Skill: Python\n",
      "   - In Demand: YES\n",
      "   - Demand Score: 8\n",
      "   - Strategy: SKILL_IN_DEMAND\n",
      "   - Related Skills Also In Demand:\n",
      "      * ML (Demand: 6)\n",
      "      * Spark (Demand: 4)\n",
      "      * PyTorch (Demand: 2)\n",
      "\n",
      "Recommended Courses:\n",
      "   1. Machine Learning with Python (Data Science) - 95.0% [HIGH DEMAND] [HIGH]\n",
      "   2. Data Analysis and Visualization (Analytics) - 80.0% [HIGH DEMAND] [HIGH]\n",
      "   3. Data Pipeline Engineering (Data Engineering) - 65.0% [HIGH DEMAND] [HIGH]\n",
      "\n",
      "============================================================\n",
      ">>> TEST 2: Employee with skill NOT IN DEMAND (COBOL)\n",
      "Profile: COBOL developer, G4\n",
      "\n",
      "Demand Analysis:\n",
      "   - Current Skill: COBOL\n",
      "   - In Demand: NO\n",
      "   - Strategy: NEED_PIVOT\n",
      "\n",
      "Recommended Courses (for skill pivot):\n",
      "   1. Full Stack Web Development (Development) - 92.9% [HIGH DEMAND]\n",
      "   2. Machine Learning with Python (Data Science) - 0.8% [HIGH DEMAND]\n",
      "   3. Data Pipeline Engineering (Data Engineering) - 0.8% [HIGH DEMAND]\n",
      "\n",
      "============================================================\n",
      ">>> TEST 3: Employee with Java skill\n",
      "Profile: Java developer, G5\n",
      "\n",
      "Demand Analysis:\n",
      "   - Current Skill: Java\n",
      "   - In Demand: YES\n",
      "   - Strategy: SKILL_IN_DEMAND\n",
      "\n",
      "Recommended Courses:\n",
      "   1. Backend API Development (Backend) - 95.0% [HIGH DEMAND]\n",
      "   2. Full Stack Web Development (Development) - 94.5% [HIGH DEMAND]\n",
      "   3. Software Architecture Design (Architecture) - 80.0% [HIGH DEMAND]\n"
     ]
    }
   ],
   "source": [
    "# Test with demand-aware recommendations\n",
    "print(\"DEMAND-AWARE COURSE RECOMMENDATION SYSTEM\")\n",
    "print(\"\")\n",
    "\n",
    "# Test Case 1: Employee with IN-DEMAND skill (Python)\n",
    "test_emp_in_demand = {\n",
    "    'Grade': 'G5',\n",
    "    'Department': 'Engineering',\n",
    "    'Primary_Skill': 'Python',  # Python is in demand\n",
    "    'Secondary_Skill': 'Django',\n",
    "    'Course_Category': 'Development',\n",
    "    'Business_Priority': 'Critical',\n",
    "    'Career_Goal': 'Full Stack Lead'\n",
    "}\n",
    "\n",
    "print(\"TEST 1: Employee with IN-DEMAND skill (Python)\")\n",
    "print(f\"Profile: {test_emp_in_demand['Primary_Skill']} developer, {test_emp_in_demand['Grade']}\")\n",
    "\n",
    "recs, analysis = recommend_course_demand_aware(test_emp_in_demand, top_n=3)\n",
    "\n",
    "print(f\"\\nDemand Analysis:\")\n",
    "print(f\"   Current Skill: {analysis['Primary_Skill']}\")\n",
    "print(f\"   In Demand: {'YES' if analysis['Is_In_Demand'] else 'NO'}\")\n",
    "print(f\"   Demand Score: {analysis['Demand_Score']}\")\n",
    "print(f\"   Strategy: {analysis.get('Strategy', 'N/A')}\")\n",
    "\n",
    "if analysis.get('Related_In_Demand'):\n",
    "    print(f\"   Related Skills Also In Demand:\")\n",
    "    for tech, score in analysis['Related_In_Demand'][:3]:\n",
    "        print(f\"      {tech} (Demand: {score})\")\n",
    "\n",
    "print(f\"\\nRecommended Courses:\")\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    demand_badge = \"[HIGH DEMAND]\" if rec['Tech_In_Demand'] else \"\"\n",
    "    relevance = f\"[{rec.get('Relevance', 'N/A')}]\"\n",
    "    print(f\"   {i}. {rec['Course_Name']} ({rec['Course_Category']}) - {rec['Confidence']:.1%} {demand_badge} {relevance}\")\n",
    "\n",
    "# Test Case 2: Employee with skill NOT in demand\n",
    "test_emp_not_demand = {\n",
    "    'Grade': 'G4',\n",
    "    'Department': 'Engineering',\n",
    "    'Primary_Skill': 'COBOL',  # Legacy, not in demand\n",
    "    'Secondary_Skill': 'Mainframe',\n",
    "    'Course_Category': 'Development',\n",
    "    'Business_Priority': 'High',\n",
    "    'Career_Goal': 'Backend Dev'\n",
    "}\n",
    "\n",
    "print(\"\\n\\nTEST 2: Employee with skill NOT IN DEMAND (COBOL)\")\n",
    "print(f\"Profile: {test_emp_not_demand['Primary_Skill']} developer, {test_emp_not_demand['Grade']}\")\n",
    "\n",
    "recs, analysis = recommend_course_demand_aware(test_emp_not_demand, top_n=3)\n",
    "\n",
    "print(f\"\\nDemand Analysis:\")\n",
    "print(f\"   Current Skill: {analysis['Primary_Skill']}\")\n",
    "print(f\"   In Demand: {'YES' if analysis['Is_In_Demand'] else 'NO'}\")\n",
    "print(f\"   Strategy: {analysis.get('Strategy', 'N/A')}\")\n",
    "\n",
    "if analysis['Alternative_Techs']:\n",
    "    print(f\"   Suggested Pivot Technologies:\")\n",
    "    for tech, score in analysis['Alternative_Techs']:\n",
    "        print(f\"      {tech} (Demand Score: {score})\")\n",
    "\n",
    "if 'Recommended_Pivot' in analysis:\n",
    "    print(f\"   Recommended Pivot: {analysis['Recommended_Pivot']}\")\n",
    "\n",
    "print(f\"\\nRecommended Courses (for skill pivot):\")\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    demand_badge = \"[HIGH DEMAND]\" if rec['Tech_In_Demand'] else \"\"\n",
    "    print(f\"   {i}. {rec['Course_Name']} ({rec['Course_Category']}) - {rec['Confidence']:.1%} {demand_badge}\")\n",
    "\n",
    "# Test Case 3: Employee with Java (check related demand)\n",
    "test_emp_java = {\n",
    "    'Grade': 'G5',\n",
    "    'Department': 'Engineering',\n",
    "    'Primary_Skill': 'Java',\n",
    "    'Secondary_Skill': 'Spring Boot',\n",
    "    'Course_Category': 'Development',\n",
    "    'Business_Priority': 'High',\n",
    "    'Career_Goal': 'Backend Lead'\n",
    "}\n",
    "\n",
    "print(\"\\n\\nTEST 3: Employee with Java skill\")\n",
    "print(f\"Profile: {test_emp_java['Primary_Skill']} developer, {test_emp_java['Grade']}\")\n",
    "\n",
    "recs, analysis = recommend_course_demand_aware(test_emp_java, top_n=3)\n",
    "\n",
    "print(f\"\\nDemand Analysis:\")\n",
    "print(f\"   Current Skill: {analysis['Primary_Skill']}\")\n",
    "print(f\"   In Demand: {'YES' if analysis['Is_In_Demand'] else 'NO'}\")\n",
    "print(f\"   Strategy: {analysis.get('Strategy', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nRecommended Courses:\")\n",
    "for i, rec in enumerate(recs, 1):\n",
    "    demand_badge = \"[HIGH DEMAND]\" if rec['Tech_In_Demand'] else \"\"\n",
    "    print(f\"   {i}. {rec['Course_Name']} ({rec['Course_Category']}) - {rec['Confidence']:.1%} {demand_badge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ad646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BENCH EMPLOYEES - DEMAND-AWARE TRAINING RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "\n",
      " Emp_Id           Name   Current_Skill In_Demand Pivot_To              Recommended_Course Confidence\n",
      "    104    Daniel Park            Java       Yes        -         Backend API Development      95.0%\n",
      "    107    George Wang      JavaScript       Yes        -      Full Stack Web Development      95.0%\n",
      "    111  Kevin O'Brien            Java       Yes        -         Backend API Development      95.0%\n",
      "    115 Oscar Martinez           Linux       Yes        -     Linux System Administration      95.0%\n",
      "    118   Rachel Green              Go       Yes        -    Software Architecture Design      95.0%\n",
      "    124    Xavier Ross         Windows        No        -      Full Stack Web Development      89.0%\n",
      "    128  Brandon Scott          Appium        No        - Automated Testing with Selenium       0.8%\n",
      "    134    Henry Adams         Tableau        No        -      Full Stack Web Development      86.3%\n",
      "    139  Maria Johnson        Cucumber        No        -      Full Stack Web Development      88.8%\n",
      "    144    Rita Wilson Robot Framework        No        -      Full Stack Web Development      89.3%\n",
      "    150   Xena Warrior         Haskell        No        -      Full Stack Web Development      94.4%\n",
      "    156   Diana Prince       Snowflake        No        - Data Analysis and Visualization      95.0%\n",
      "    162  Julia Roberts            Okta        No        -      Full Stack Web Development      89.3%\n",
      "    168   Priya Sharma          Blazor        No        -         Backend API Development      95.0%\n",
      "    176    Xander Cage             H2O        No        -      Full Stack Web Development      88.7%\n",
      "\n",
      "SUMMARY:\n",
      "   - Total Bench Employees Analyzed: 15\n",
      "   - Skills Already In Demand: 5\n",
      "   - Recommended for Skill Pivot: 0\n"
     ]
    }
   ],
   "source": [
    "# Process BENCH employees with demand-aware recommendations\n",
    "print(\"BENCH EMPLOYEES - DEMAND-AWARE TRAINING RECOMMENDATIONS\")\n",
    "print(\"\")\n",
    "\n",
    "# Sample bench employees for demonstration\n",
    "sample_bench = bench_df_clean.head(15).copy()\n",
    "\n",
    "results = []\n",
    "for _, emp in sample_bench.iterrows():\n",
    "    emp_profile = {\n",
    "        'Emp_Id': emp['Emp_Id'],\n",
    "        'Grade': emp['Grade'],\n",
    "        'Department': emp['Department'],\n",
    "        'Primary_Skill': emp['Primary_Skill'],\n",
    "        'Secondary_Skill': emp.get('Secondary_Skill', emp['Primary_Skill']),\n",
    "        'Location': emp['Location'],\n",
    "        'Course_Category': 'Development',  # Default\n",
    "        'Business_Priority': 'High',\n",
    "        'Career_Goal': 'Senior Developer'\n",
    "    }\n",
    "    \n",
    "    recs, analysis = recommend_course_demand_aware(emp_profile, top_n=1)\n",
    "    \n",
    "    results.append({\n",
    "        'Emp_Id': emp['Emp_Id'],\n",
    "        'Name': emp['Employee_Name'],\n",
    "        'Current_Skill': emp['Primary_Skill'],\n",
    "        'In_Demand': 'Yes' if analysis['Is_In_Demand'] else 'No',\n",
    "        'Pivot_To': analysis.get('Recommended_Pivot', '-'),\n",
    "        'Recommended_Course': recs[0]['Course_Name'] if recs else 'N/A',\n",
    "        'Confidence': f\"{recs[0]['Confidence']:.1%}\" if recs else 'N/A'\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\n\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Summary statistics\n",
    "in_demand_count = sum(1 for r in results if r['In_Demand'] == 'Yes')\n",
    "pivot_count = sum(1 for r in results if r['Pivot_To'] != '-')\n",
    "\n",
    "print(f\"\\nSUMMARY:\")\n",
    "print(f\"   Total Bench Employees Analyzed: {len(results)}\")\n",
    "print(f\"   Skills Already In Demand: {in_demand_count}\")\n",
    "print(f\"   Recommended for Skill Pivot: {pivot_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b62d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DEMAND-AWARE RECOMMENDATION TEST RESULTS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Emp_Id            Name        Skill In_Demand Pivot                    Course Match\n",
      "  E901   Alex Thompson       Python       Yes     - Machine Learning with Pyt  MISS\n",
      "  E902    Priya Sharma Machine Lear        No     - Machine Learning with Pyt MATCH\n",
      "  E903  Marcus Johnson   JavaScript       Yes     - Full Stack Web Developmen MATCH\n",
      "  E904   Lisa Anderson          AWS       Yes     -    AWS Cloud Practitioner MATCH\n",
      "  E905     Rahul Verma          SQL       Yes     - Data Analysis and Visuali MATCH\n",
      "  E906 Sophia Martinez         Java       Yes     -   Backend API Development MATCH\n",
      "  E907   Carlos Rivera     Selenium       Yes     - Automated Testing with Se MATCH\n",
      "  E908   Jennifer Wong      Node.js       Yes     -   Backend API Development  MISS\n",
      "  E909    Ahmed Hassan        Spark       Yes     - Data Pipeline Engineering MATCH\n",
      "  E910      Emily Chen           Go       Yes     - Software Architecture Des  MISS\n",
      "  E911     Tom Bradley        COBOL        No     - Full Stack Web Developmen  MISS\n",
      "  E912   Natasha Patel         Perl        No     - Full Stack Web Developmen  MISS\n",
      "  E913       David Kim       Delphi        No     - Full Stack Web Developmen MATCH\n",
      "  E914    Maria Santos Visual Basic        No     - Full Stack Web Developmen  MISS\n",
      "  E915     Ryan Cooper   ColdFusion        No     - Full Stack Web Developmen MATCH\n",
      "  E916  Sarah Mitchell      Flutter        No     - Full Stack Web Developmen MATCH\n",
      "  E917    James Wilson   TensorFlow       Yes     - Machine Learning with Pyt MATCH\n",
      "  E918   Anna Kowalski      Fortran        No     - Full Stack Web Developmen  MISS\n",
      "  E919      Mike Brown       Docker       Yes     - DevOps and CI/CD Pipeline MATCH\n",
      "  E920    Linda Garcia ActionScript        No     - Full Stack Web Developmen MATCH\n",
      "  E921    Chris Taylor        Azure       Yes     -    AWS Cloud Practitioner MATCH\n",
      "  E922     Jessica Lee  Objective-C        No     - Full Stack Web Developmen MATCH\n",
      "  E923 Robert Martinez        Kafka       Yes     - Data Pipeline Engineering MATCH\n",
      "  E924  Michelle Adams          QTP        No     - Automated Testing with Se MATCH\n",
      "  E925     Daniel Park    Terraform       Yes     -    AWS Cloud Practitioner MATCH\n",
      "  E926     Karen White  Silverlight        No     - Full Stack Web Developmen MATCH\n",
      "  E927    Steven Clark Cybersecurit       Yes     -  Cybersecurity Essentials MATCH\n",
      "  E928  Nancy Thompson       FoxPro        No     - Full Stack Web Developmen  MISS\n",
      "  E929  Paul Rodriguez      GraphQL        No     -   Backend API Development MATCH\n",
      "  E930   Betty Johnson PowerBuilder        No     - Full Stack Web Developmen MATCH\n",
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "Total Test Cases: 30\n",
      "Course Predictions Matched: 22/30 (73.3%)\n",
      "Demand Status Correct: 27/30 (90.0%)\n",
      "Pivot Recommendations Correct: 18/30 (60.0%)\n",
      "\n",
      "Test Case Breakdown:\n",
      "   - IN_DEMAND scenarios: 18\n",
      "   - NOT_IN_DEMAND scenarios (pivot needed): 12\n"
     ]
    }
   ],
   "source": [
    "# Test with JSON file - DEMAND-AWARE validation\n",
    "import json\n",
    "\n",
    "with open('test_employees.json', 'r') as f:\n",
    "    test_records = json.load(f)\n",
    "\n",
    "print(\"DEMAND-AWARE RECOMMENDATION TEST RESULTS\")\n",
    "print(\"\")\n",
    "\n",
    "course_match_count = 0\n",
    "demand_match_count = 0\n",
    "pivot_match_count = 0\n",
    "total = len(test_records)\n",
    "\n",
    "results_summary = []\n",
    "\n",
    "for emp in test_records:\n",
    "    emp_id = emp.get('Emp_Id')\n",
    "    name = emp.get('Employee_Name')\n",
    "    expected_course = emp.get('Expected_Course')\n",
    "    expected_in_demand = emp.get('Skill_In_Demand', True)\n",
    "    expected_pivot = emp.get('Expected_Pivot')\n",
    "    scenario = emp.get('Test_Scenario', '')\n",
    "    \n",
    "    # Get demand-aware recommendations\n",
    "    recs, analysis = recommend_course_demand_aware(emp, top_n=1)\n",
    "    \n",
    "    predicted_course = recs[0]['Course_Name'] if recs else 'N/A'\n",
    "    actual_in_demand = analysis['Is_In_Demand']\n",
    "    actual_pivot = analysis.get('Recommended_Pivot')\n",
    "    \n",
    "    # Check matches\n",
    "    course_matched = predicted_course == expected_course\n",
    "    demand_matched = actual_in_demand == expected_in_demand\n",
    "    pivot_matched = (expected_pivot is None and actual_pivot is None) or \\\n",
    "                   (expected_pivot and actual_pivot and expected_pivot.lower() in actual_pivot.lower())\n",
    "    \n",
    "    if course_matched:\n",
    "        course_match_count += 1\n",
    "    if demand_matched:\n",
    "        demand_match_count += 1\n",
    "    if pivot_matched:\n",
    "        pivot_match_count += 1\n",
    "    \n",
    "    # Status indicators\n",
    "    course_status = \"MATCH\" if course_matched else \"MISS\"\n",
    "    demand_status = \"MATCH\" if demand_matched else \"MISS\"\n",
    "    pivot_status = \"MATCH\" if pivot_matched else \"WARN\"\n",
    "    \n",
    "    results_summary.append({\n",
    "        'Emp_Id': emp_id,\n",
    "        'Name': name[:15],\n",
    "        'Skill': emp.get('Primary_Skill')[:12],\n",
    "        'In_Demand': 'Yes' if actual_in_demand else 'No',\n",
    "        'Pivot': actual_pivot[:10] if actual_pivot else '-',\n",
    "        'Course': predicted_course[:25],\n",
    "        'Match': course_status\n",
    "    })\n",
    "\n",
    "# Print results table\n",
    "print(\"\\n\")\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSUMMARY\")\n",
    "print(f\"Total Test Cases: {total}\")\n",
    "print(f\"Course Predictions Matched: {course_match_count}/{total} ({course_match_count/total*100:.1f}%)\")\n",
    "print(f\"Demand Status Correct: {demand_match_count}/{total} ({demand_match_count/total*100:.1f}%)\")\n",
    "print(f\"Pivot Recommendations Correct: {pivot_match_count}/{total} ({pivot_match_count/total*100:.1f}%)\")\n",
    "\n",
    "# Breakdown by scenario type\n",
    "in_demand_cases = [e for e in test_records if e.get('Skill_In_Demand', True)]\n",
    "not_in_demand_cases = [e for e in test_records if not e.get('Skill_In_Demand', True)]\n",
    "print(f\"\\nTest Case Breakdown:\")\n",
    "print(f\"   IN_DEMAND scenarios: {len(in_demand_cases)}\")\n",
    "print(f\"   NOT_IN_DEMAND scenarios (pivot needed): {len(not_in_demand_cases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46061aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INDIVIDUAL EMPLOYEE LOOKUP\n",
      "============================================================\n",
      "\n",
      "Employee ID: 104\n",
      "   Current Skill: Java\n",
      "   In Demand: YES\n",
      "\n",
      "   Training Recommendations:\n",
      "      1. Backend API Development - 95.0%\n",
      "      2. Full Stack Web Development - 93.3%\n",
      "      3. Software Architecture Design - 80.0%\n"
     ]
    }
   ],
   "source": [
    "# Full function to get recommendation for any employee (bench or otherwise)\n",
    "def get_training_recommendation(emp_id=None, emp_name=None, from_bench=True):\n",
    "    \"\"\"\n",
    "    Get demand-aware training recommendations for an employee.\n",
    "    Can lookup from bench data or accept custom profile.\n",
    "    \"\"\"\n",
    "    if from_bench and (emp_id or emp_name):\n",
    "        # Find employee in bench data\n",
    "        if emp_id:\n",
    "            emp_row = bench_df_clean[bench_df_clean['Emp_Id'] == emp_id]\n",
    "        else:\n",
    "            emp_row = bench_df_clean[bench_df_clean['Employee_Name'].str.contains(emp_name, case=False, na=False)]\n",
    "        \n",
    "        if emp_row.empty:\n",
    "            return None, f\"Employee not found in bench data\"\n",
    "        \n",
    "        emp = emp_row.iloc[0]\n",
    "        profile = {\n",
    "            'Grade': emp['Grade'],\n",
    "            'Department': emp['Department'],\n",
    "            'Primary_Skill': emp['Primary_Skill'],\n",
    "            'Secondary_Skill': emp.get('Secondary_Skill', emp['Primary_Skill']),\n",
    "            'Course_Category': 'Development',\n",
    "            'Business_Priority': 'High',\n",
    "            'Career_Goal': 'Senior Developer'\n",
    "        }\n",
    "    else:\n",
    "        return None, \"Please provide emp_id or emp_name\"\n",
    "    \n",
    "    return recommend_course_demand_aware(profile, top_n=3)\n",
    "\n",
    "# Example usage\n",
    "print(\"INDIVIDUAL EMPLOYEE LOOKUP\")\n",
    "print(\"\")\n",
    "\n",
    "# Lookup a specific bench employee\n",
    "recs, analysis = get_training_recommendation(emp_id=104)\n",
    "if recs:\n",
    "    print(f\"Employee ID: 104\")\n",
    "    print(f\"   Current Skill: {analysis['Primary_Skill']}\")\n",
    "    print(f\"   In Demand: {'YES' if analysis['Is_In_Demand'] else 'NO'}\")\n",
    "    if analysis.get('Recommended_Pivot'):\n",
    "        print(f\"   Pivot Recommendation: {analysis['Recommended_Pivot']}\")\n",
    "    print(f\"\\n   Training Recommendations:\")\n",
    "    for i, rec in enumerate(recs, 1):\n",
    "        print(f\"      {i}. {rec['Course_Name']} - {rec['Confidence']:.1%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
